# Getting Started with Data Engineering


## Введение
Всем привет! Меня зовут Дмитрий Аношин. 

Вот уже 4 года я работаю дата инженером в Amazon. Когда я в 2016 году начинал работать на позиции data engineer, я особо не вдавался в подробности, что это за роль. Просто искал работу в области данных, желательно Business Intelligence разработчиком. А получилось найти позицию data engineer в Amazon. Частично мне повезло, частично это было заслуженно, так как с 2010 года я непрерывно учился и развивался в области аналитики. 

Я преследовал несколько целей:
1. Получать хорошую зарплату.
2. Работать в хорошей компании.
3. Работать за границей, желательно близко к морю или океану.

Поэтому очень важно на начальном этапе *определиться с целью*. Именно цель даст вам силы и мотивацию для её достижения. 

Сейчас очень много "мусора" в онлайне и в офлайне, все готовы вас научить. Обычно по принципу "утром деньги - вечером стулья": то есть сначала вы платите за курс, а там - как повезет. 

Сам я читал множество книг, смотрел обучающие видео и проходил курсы на Coursera и edX. И зачастую курс бывает "формальный", неинтересный, скучный. Я бы не хотел сделать еще один скучный курс, поэтому этот курс будет меняться и эволюционировать, у него могут появляться новые модули и изменяться старые.

Я не преследую цели научить всех и не преследую цели зарабатывать на студентах. Так сложилось, что за свою карьеру я помог 8-ми знакомым пройти путь с нуля до трудоустройства, и 6 из них до сих пор успешно работают с данными. 

Меня до сих пор спрашивают: как научиться, как начать? И чтобы не рассказывать снова и снова одно и то же многократно, я решил сконцентрировать эти знания на ресурсе `datalearn`. Я не являюсь супер-экспертом в какой-то области и всё, о чем я говорю, - это моё восприятие роли аналитики, данных и инструментов аналитики для помощи бизнесу. 

Как я уже говорил, курс бесплатный, так как он ничего не гарантирует. Но я уверен: он работает, так как позволит вам сфокусироваться на важном и отбросить всё лишнее, но при условии, что у вас есть цель и вы готовы реально поднапрячься, так как основная нагрузка ложится именно на ваши плечи. 

Также хотелось бы создать *экосистему* - не просто набор видео лекций и упражнений, но framework, в котором люди могут помогать друг другу с решением задач и упражнений и делиться опытом. Будет просто замечательно, если вы станете *data ambasador* и будете принимать участие в создании, исправлении и добавлении контента. 

Еще один важный для меня момент - это возможность делиться западным опытом с русскоязычным комьюнити, рассказывать о популярных на западе технологиях и решениях, помогать подготовиться собеседованию западную компанию, например в Амазон. 

Если задуматься над вопросом *"что самое ценное в курсе?"*, то я бы отметил 2 момента:
1. Понимание задачи бизнеса и умение подобрать правильную (оптимальную) технологию для ее достижения.
2. Понимание базовых принципов аналитики.

Если по результату курса вы сможете ответить на эти два вопроса, то остальное - уже дело техники и гугл вам в помощь.

По окончании курса планируются сертификаты для всех, кто успешно справится со всеми заданиями (промежуточными заданиями модулей и итоговым заданием). 
Итоговое задание будет включать в себя проект сквозной аналитики.


## Курсы Data learn
На начальном этапе существует 2 курса, которые взаимосвязаны:
1) `Getting Started with Data Engineering` - курс про мою работу инженером данных. Если бы я брал на работу инженера данных, я бы хотел, чтобы он обладал знаниями и компетенциями, которые мы затронем в курсе.

2) `Data Literacy` - это совсем базовый курс для тех, кто совсем не работал с данными (никогда) и вот ему пришлось. Задачки могут быть уровня открыть отчет и прочитать его, понять о чём он, как им пользоваться. То есть основы аналитики для менеджеров бизнес-подразделений. 

Так как оба курса создаются одним автором, то между ними будет большое пересечение.

Также мне хотелось бы выделить еще один элемент - Аналитика для Женщин. Это не столько курс, сколько community. Я вижу большой спрос на такого рода сообщества на западе и я подумал, что было бы классно иметь такое в русскоязычном сообществе для того, чтобы прекрасная половина могла изучать аналитику и технологии в своей комфортной зоне и со своей скоростью. Я бы хотел, чтобы нашлись заинтересованные девушки, кто будет развивать это направление, а я бы помогал с контентом (на данном этапе в этом направлении пока ничего не делается).

Если первые два курса хорошо зайдут, то можно будет добавить специализации по отдельным технологиям или углубляться в отдельные модули, например Python, Spark, Streaming, Cloud и многое другое. Возможно, появятся заинтересованные люди, которые захотят создать свои курсы.

Также у нас есть отличная возможность проводить вебинары и приглашать спикеров со всего мира. Возможно, получится даже привлечь компании, которые будут заинтересованы в специалистах. Да и само сообщество должно помочь в поиске работы и сотрудников.

Еще из интересного - хотелось бы сделать несколько отдельных дополнительных курсов: 
* По подготовке резюме, поиску работы и прохождению собеседований для аналитических специальностей.
* По подготовке менеджеров для управления аналитической командой. По моему опыту, тут уже требуются другие навыки, так как технические навыки руководителей часто вынужденно уходят на второй план, уступая место благополучию команды и вовлеченности каждого ее члена.

**Сложно осуществить всё задуманное в одиночку, будьте проактивными и помогайте!**


# Требования
Я уже писал про требования к курсам в нашем Slack:
- доступ в интернет;)
- экран 15" и больше;
- 16 Gb оперативки, иначе будет тормозить; 
- операционные системы Windows и Maс. Linux тоже пойдет;
- чтобы получить доступ к AWS, возможно, понадобится ввести номер банковской карты при регистрации;
- знание английского на уровне чтения;
- умение гуглить;)
- наличие социальной сети, чтобы рассказать о курсе;
- slack;
- акаунт github.

Например, если вы не знаете Английский, но хотите работать в этой области, то вам следует начать его изучать и активно практиковать. 

В России есть yandex и mail cloud, я с ними не работал, и мне кажется они пока сыроваты для аналитики. 


# Подготовка к курсу по Data Engineering
Есть некоторые вещи, которые важно (или как минимум желательно) знать для успешного прохождения курса. 
Во время курса мы будем их разбирать, но будет хорошо, если вы уже владеете начальными навыками:

- **Excel**. Это универсальный инструмент для работы с данными. Если вы никогда с ним не работали, найдите любой ресурс и потренируйтесь. Страница Excel - это таблица со строками и столбцами, в которых можно выполнять операции над данными. Отличная аналогия для баз данных и хранилищ данных. Также в Excel можно создавать графики и Pivot (вы знаете, что это?) - это уже как BI инструмент.

- **SQL**. Самый важный для меня элемент. Чтобы там ни говорили про Python/Scala/Java, большинство компаний (тот же Амазон) имеют базы данных. И бизнес-пользователи, и аналитики используют SQL для получения данных. Мне нравится ресурс `sql-ex.ru`. Там есть множество упражнений, достаточно сделать около 30, чтобы понять, как используются `SELECT`, `FROM`, `GROUP BY`, `ORDER BY`, `HAVING`, `UNION`, `JOIN`, подзапросы. Этого хватит с головой! Есть и множество других ресурсов.

- **Python**. Так сложилось, что Python стал главный языком для инжиниринга данных, но не главнее SQL. С Python можно сделать все: от графика/отчета, до инструмента трансформации данных, Machine Learning модели и т.п. Я склоняюсь к тому, что Python - это уже следующий уровень, сначала надо знать SQL. Например, 80% моей работы Data Engineer - это использование SQL, так как данные либо в озере данных, либо в хранилище данных. В редких случаях нужен Spark (PySpark или Scala). 

- **CLI**. Command line interface, или командная строка. Это важный навык, так как зачастую программы установлены на Linux машинах без графического интерфейса (или на удалённых серверах), и нужно консольными  командами перемещаться по папкам и запускать программы. Вот отличный курс: [Introduction to Shell](https://www.datacamp.com/courses/introduction-to-shell-for-data-science).

- **GitHub**. Так как мы используем гитхаб как учебник, то обязательно посмотрите, как он работает. Сам по себе гит очень популярен для разработчиков, чтобы хранить код или делать code review (смотреть изменения в коде). Он хорошо работает для SQL, Python, но не работает для приложений вроде Tabelau и PowerBI. Вот [инструкция на русском](http://bi0morph.github.io/hello-world/).


# Модуль 1: Роль Аналитики в Организации
## 1.1: Введение

## 1.2: Роль аналитики в организации

## 1.3: Задачи аналитики

## 1.4: MindMap инжиниринга данных

## 1.5: Основные роли в аналитике

## 1.6: Два типа инженера данных
Мне очень нравится слово ИНЖЕНЕР. Я сам по специальности Инженер-конструктор. Для меня инженер - это профессионал, который может посмотреть на предмет и мысленно его разобрать на составные части, найти неисправность в неработающем предмете или создать новый предмет на базе требований заказчика, используя свои профессиональные инструменты. 

Инженер не знает всё обо всём, он понимает базовые принципы и видит конечную цель, а дальше с использованием инструментария и навыков он творит.

Инженеры бывают разные, мы будет говорить про инженеров, которые работают с данными. Не знаю, как у вас, но до Амазона я термин *data engineer* не использовал, вместо инженера были просто *разработчики* и *специалисты*:
- Разработчик ПО
- Разработчик Отчетов
- Специалист data mining
- BI Разработчик
- ETL разработчик
- DW разработчик

И еще были *архитекторы*: все те же слова, но с дополнением "архитектор" - это значит уже опытный специалист, который может не просто что-то делать, но и создавать архитектуру решения (DW, BI, ETL).

Прежде всего, для меня существует два типа Инженера Данных:
1.	Программист, который стал Инженером Данных.
2.	BI/DW/ETL-разработчик, который стал Инженером Данных.

Давайте подробнее рассмотрим отличия. Задача Инженера Данных - создание платформы, куда автоматически загружаются данные, там они трансформируются в доступную форму для конечных пользователей (как правило, бизнес-пользователей). 

Источники данных могут быть различными: реляционные базы данных, SFTP, API, файлы с логами, сенсоры. Типа данных также могут быть различными: структурированные данные в табличном формате, полуструктурированные (JSON, XML) и неструктурированные (видео, аудио).

В зависимости от бизнес-требований, Инженеру Данных необходимо создать поток данных (data pipeline), который автоматически будет забирать данные и загружать их в платформу данных (хранилище данных или озеро данных). Вам необходимо выбрать инструменты для работы с данными. 

Цель у нас простая: помочь бизнесу извлечь ценную информацию из данных. Для этого нужно создать аналитическое решение, где пользователи могут самостоятельно работать с данными, проверять свои гипотезы и анализировать бизнес-задачи, используя правильные метрики. 

Чтобы построить такое решение, нужен Инженер Данных. В моем случает это не просто создание потока данных, трансформация и загрузка данных. Это полноценная работа с бизнес-подразделениями, понимание их нужд и предоставление им инструментов для решения их задач. 

Я имею в виду весь цикл построения аналитического решения. Именно это мы будем изучать на курсе. 

И теперь самое интересное: в зависимости от вашего опыта, вы можете использовать языки программирования Java/Python и т.д. для создания решения - Инженер Данных №1 (*Technical Data Engineer*), а можете использовать готовые решения, которые позволят вам создавать масштабируемые и безопасные решения, быстро достигать результатов - Инженер Данных №2 (пусть будет *Result Oriented Data Engineer*). 

Без программирования не обойтись даже для 2-го типа, но вам не нужно быть гуру программирования, достаточно понимать, как работает Python, и использовать небольшие куски кода для кастомизации решения. 

**Главное в этом курсе не зубрежка программирования или конкретного продукта, а понимание принципов работы с данными, классов инструментов и возможных бизнес-задач и пути их решения, а для всего остального есть Google;)**


## 1.7: Обзор вакансий Amazon и hh.ru

## 1.8: Архитектура аналитического решения

## Домашнее задание
В качестве домашнего задания нужно установить `git`, создать аккаунт на `GitHub`, нарисовать архитектуру решения в `drawio` и построить дашборд на базе файлика, который нужно синхронизировать со своим локальным компьютером, используя `git`.


# Модуль 2: Построение Аналитического Решения с помощью подручных средств
## 2.1: Введение
Рассмотрим пример решения для локальной аналитики. 
Познакомимся с базами данных, и поймем их преимущество для работы с данными по сравнению с Excel/Google Sheets. 
Потренируемся на SQL, установим базу данных и загрузим в нее данные, потом будем использовать Excel/Google Sheets для визуализации данных.

## 2.2: Что такое базы данных и как они помогают при работе с данными

## 2.3: OLTP vs MOLAP vs ROLAP vs DW vs raw files

## 2.4: Язык SQL для работы с базами данных

## 2.5: Как мы подключаемся к базам данных

## 2.6: Как донести данные до бизнес-пользователя

## 2.7: Пример решений на Klip Folio, Google Sheets и тп

## Домашнее задание

# Модуль 3: Знакомство с Современным Аналитическим Решением и облачной аналитикой

# Модуль 4: Оптимизация Хранилища данных

# Модуль 5: Интеграция данных и создание потоков данных (data piplelines)

# Модуль 6: Выбор и подключение Business Intelligence решения

# Модуль 7: Знакомство с Apache Spark

# Модуль 8: Создание решения для Big Data с использованием Hadoop и Spark

# Модуль 9: Знакомство с понятием Озера Данных и его создание с помощью инструментов AWS

# Модуль 10: Решение задачи по стримингу данных

# Модуль 11: Задачи Машинного Обучения глазами инженера данных

# Модуль 12: Лучшие практики инженера данных
